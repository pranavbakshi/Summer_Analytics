{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNP97dflSJpzSQVLXcQmSRZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranavbakshi/Summer_Analytics/blob/main/summer_analytics_mid_hackathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.signal import savgol_filter\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def preprocess_ndvi(df, is_train=True, class_map=None):\n",
        "    ndvi_cols = [col for col in df.columns if \"_N\" in col]\n",
        "\n",
        "    df[ndvi_cols] = df[ndvi_cols].interpolate(axis=1).bfill(axis=1).ffill(axis=1)\n",
        "\n",
        "    def smart_smooth(row):\n",
        "        if isinstance(row, pd.Series):\n",
        "            if row.isnull().all():\n",
        "                return np.full_like(row.values, np.nan)\n",
        "            elif row.isnull().mean() > 0.5:\n",
        "                 median_val = row.median()\n",
        "                 return np.full_like(row.values, median_val if pd.notnull(median_val) else np.nan)\n",
        "\n",
        "            try:\n",
        "                smoothed_row = savgol_filter(row.values[~np.isnan(row.values)], 5, 2)\n",
        "\n",
        "                result = np.full_like(row.values, np.nan)\n",
        "                result[~np.isnan(row.values)] = smoothed_row\n",
        "                return result\n",
        "\n",
        "            except Exception as e:\n",
        "                return row.values\n",
        "        else:\n",
        "            return row\n",
        "\n",
        "    smoothed_data = df[ndvi_cols].apply(lambda row: smart_smooth(row), axis=1, result_type='broadcast')\n",
        "    df[ndvi_cols] = smoothed_data\n",
        "\n",
        "\n",
        "    if not is_train and class_map:\n",
        "        for col in ndvi_cols:\n",
        "            # Corrected indentation for the else block\n",
        "            if col in class_map:\n",
        "                 df[col] = df[col].fillna(class_map[col])\n",
        "            else:\n",
        "                 print(f\"Warning: Column {col} not found in class_map. Cannot fill NaNs.\")\n",
        "\n",
        "\n",
        "    return df\n",
        "\n",
        "train = pd.read_csv(\"/content/hacktrain.csv\")\n",
        "test = pd.read_csv(\"/content/hacktest.csv\")\n",
        "\n",
        "train = preprocess_ndvi(train.copy())\n",
        "ndvi_cols = [col for col in train.columns if \"_N\" in col]\n",
        "if 'class' in train.columns:\n",
        "    class_ndvi_map = train.groupby('class')[ndvi_cols].median()\n",
        "    class_ndvi_map = class_ndvi_map.mean().to_dict()\n",
        "\n",
        "    test = preprocess_ndvi(test.copy(), is_train=False, class_map=class_ndvi_map)\n",
        "else:\n",
        "    print(\"Warning: 'class' column not found in train after initial load. Cannot create class_ndvi_map.\")\n",
        "    class_ndvi_map = None\n",
        "    test = preprocess_ndvi(test.copy(), is_train=False, class_map=None)\n",
        "\n",
        "\n",
        "def extract_features(df):\n",
        "    ndvi_cols = [col for col in df.columns if \"_N\" in col]\n",
        "    if not ndvi_cols:\n",
        "        print(\"Warning: No NDVI columns found for feature extraction.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    x = np.arange(len(ndvi_cols))\n",
        "\n",
        "    stats = pd.DataFrame()\n",
        "    try:\n",
        "        ndvi_vals = df[ndvi_cols]\n",
        "    except KeyError:\n",
        "        print(\"Error: Some NDVI columns not found in DataFrame.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "    if not ndvi_vals.empty:\n",
        "        stats['ndvi_mean'] = ndvi_vals.mean(axis=1)\n",
        "        stats['ndvi_std'] = ndvi_vals.std(axis=1)\n",
        "        stats['ndvi_max'] = ndvi_vals.max(axis=1)\n",
        "        stats['ndvi_min'] = ndvi_vals.min(axis=1)\n",
        "        stats['ndvi_trend'] = ndvi_vals.apply(\n",
        "            lambda r: np.polyfit(x[~np.isnan(r)], r[~np.isnan(r)], 1)[0] if len(r[~np.isnan(r)]) >= 2 else np.nan, axis=1\n",
        "            )\n",
        "        stats['ndvi_range'] = stats['ndvi_max'] - stats['ndvi_min']\n",
        "\n",
        "        cut1, cut2 = len(ndvi_cols) // 3, 2 * len(ndvi_cols) // 3\n",
        "        for i, (start, end) in enumerate([(0, cut1), (cut1, cut2), (cut2, len(ndvi_cols))]):\n",
        "            segment = ndvi_vals.iloc[:, start:end]\n",
        "            if not segment.empty:\n",
        "                stats[f'seg_{i}_mean'] = segment.mean(axis=1)\n",
        "                stats[f'seg_{i}_std'] = segment.std(axis=1)\n",
        "                stats[f'seg_{i}_max'] = segment.max(axis=1)\n",
        "            else:\n",
        "                 stats[f'seg_{i}_mean'] = np.nan\n",
        "                 stats[f'seg_{i}_std'] = np.nan\n",
        "                 stats[f'seg_{i}_max'] = np.nan\n",
        "\n",
        "\n",
        "        def get_peak_time(row, columns):\n",
        "            if row.isnull().all():\n",
        "                return np.nan\n",
        "            try:\n",
        "                peak_idx = np.argmax(row.values)\n",
        "                peak_col = columns[peak_idx]\n",
        "                return int(peak_col[:6])\n",
        "            except Exception as e:\n",
        "                return np.nan\n",
        "\n",
        "        stats['ndvi_peak_time'] = ndvi_vals.apply(\n",
        "            lambda r: get_peak_time(r, ndvi_vals.columns), axis=1\n",
        "        )\n",
        "\n",
        "\n",
        "        stats['ndvi_peak_month'] = stats['ndvi_peak_time'].apply(lambda x: x % 100 if pd.notnull(x) else np.nan)\n",
        "    else:\n",
        "         print(\"Warning: ndvi_vals is empty after selecting columns. No stats extracted.\")\n",
        "         return stats\n",
        "\n",
        "\n",
        "    return stats\n",
        "\n",
        "X_train = extract_features(train)\n",
        "X_test = extract_features(test)\n",
        "\n",
        "if X_train.isnull().any().any():\n",
        "    print(\"Warning: NaNs found in X_train after feature extraction. Imputing with mean.\")\n",
        "    imputation_means = X_train.mean()\n",
        "    X_train = X_train.fillna(imputation_means)\n",
        "\n",
        "if X_test.isnull().any().any():\n",
        "     print(\"Warning: NaNs found in X_test after feature extraction. Imputing with mean from train data.\")\n",
        "     X_test = X_test.fillna(imputation_means)\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "if 'class' in train.columns:\n",
        "    y = le.fit_transform(train['class'])\n",
        "else:\n",
        "    print(\"Error: 'class' column not found in train. Cannot fit LabelEncoder.\")\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=0.95, random_state=42)\n",
        "\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "if 'y' in locals():\n",
        "    X_tr, X_val, y_tr, y_val = train_test_split(X_train_pca, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "    model = LogisticRegression(max_iter=3000, multi_class='multinomial', solver='lbfgs', random_state=42)\n",
        "    model.fit(X_tr, y_tr)\n",
        "\n",
        "    y_pred = model.predict(X_val)\n",
        "    print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
        "    print(classification_report(y_val, y_pred, target_names=le.classes_))\n",
        "\n",
        "\n",
        "    test_pred = model.predict(X_test_pca)\n",
        "\n",
        "    submission = pd.DataFrame({\n",
        "        'ID': test['ID'],\n",
        "        'class': le.inverse_transform(test_pred)\n",
        "    })\n",
        "\n",
        "    submission.to_csv(\"submission.csv\", index=False)\n",
        "    print(\"Submission saved as 'submission.csv'\")\n",
        "else:\n",
        "    print(\"Skipping model training and submission due to missing 'y' (class column).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-Y34UQD1S_i",
        "outputId": "b1ad737c-77a9-45fe-af38-5ceb8cff563a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.84125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        farm       0.40      0.14      0.20       168\n",
            "      forest       0.86      0.97      0.92      1232\n",
            "       grass       0.00      0.00      0.00        39\n",
            "  impervious       0.79      0.82      0.81       134\n",
            "     orchard       0.00      0.00      0.00         6\n",
            "       water       0.86      0.57      0.69        21\n",
            "\n",
            "    accuracy                           0.84      1600\n",
            "   macro avg       0.49      0.42      0.44      1600\n",
            "weighted avg       0.79      0.84      0.80      1600\n",
            "\n",
            "Submission saved as 'submission.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}